<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Exploring Gaussian Splatting - jos√© pedro dias</title>
    <meta name="viewport" content="width=device-width, initial-scale=0.8" />
    <link rel="icon" href="data:,">
    <link rel="stylesheet" href="/main.css">
    <link rel="alternate" type="application/rss+xml" href="https://josepedrodias.com/posts/feed.xml" />
  </head>
  <body class="blog">
<h1>Exploring Gaussian Splatting</h1>
<p>I spent the whole saturday capturing and creating 3D scenes using gaussian splatting (GS) and photogrammetry (PG). These are my findings.</p>
<p>I used my iPhone 13 pro to take photos and videos and used both the <a href="https://github.com/jonstephens85/gaussian-splatting-Windows">windows branch by John Stevens</a> for generating the gaussian splats and <a href="https://colmap.github.io/">colmap</a> alone to do photogrammetry counterparts of the same content and compare. I say alone because colmap is used to do the early stages of GS too.</p>
<p>I kept my camera&#39;s exposure locked throughout the session. I never used zoom and tried to overlap 1/3 of the image on most shots.
One useful thing I did early on was to edit train.py so it creates a couple of early results before the 30k final one: mine now does 2500, 10k and the final 30k. Also prepared a batch script to easily open the viewer as soon as each intermediate result gets ready, so one can immediately grasp whether the cam estimations are working and the ongoing work is worth waiting for. I noticed that in the occasions the training step started to slow down considerably, the algorithm was estimating loads of garbage. In such cases abort early and either try again or improve your input capture material...</p>
<p>I started by assuming I could work my way by taking ~20 pictures with a couple of overlap and maximize the angles over the subject. That&#39;s how I captured the initial models.</p>
<h2>wooden house</h2>
<p><a href="2023-10-08/casa.jpg"><img src="2023-10-08/casa.jpg" alt="wooden house source images" title="wooden house" width="50%"></a></p>
<iframe src="https://player.vimeo.com/video/872320780?badge=0&amp;autopause=0&amp;quality_selector=1&amp;progress_bar=1&amp;player_id=0&amp;app_id=58479" width="1280" height="720" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" title="wooden house - checking GS results"></iframe>

<p><a href="https://josepedrodias.com/gaussian/#1">wooden house GS</a></p>
<img src="2023-10-08/casa_pg.png" alt="wooden house photogrammetry" title="wooden house photogrammetry" width="50%">

<p>The first subject was a small wooden house I have. This one worked great - I managed to control the setup, both the sofa below it and the house surface are rough which surely helped identifying singularity points better.
I then tried to use photogrammetry to see how well that would fare against GS. Used <a href="https://www.meshlab.net/">meshlab</a> to rotate the model and remove irrelevant geometry. Very decent result - holes aren&#39;t fully carved and the surface is a bit bumpy but I haven&#39;t attempted decimation or other simplification steps. Also it was super fast - medium quality poisson mesher took 5 min. I suppose simple subjects work well on both!</p>
<p>I then went outside and captured 2 subjects: a very large tree and 3 facades of the building I live on.</p>
<h2>a tree</h2>
<p><a href="2023-10-08/tree.jpg"><img src="2023-10-08/tree.jpg" alt="tree source images" title="tree" width="50%"></a></p>
<iframe src="https://player.vimeo.com/video/872320550?badge=0&amp;autopause=0&amp;quality_selector=1&amp;progress_bar=1&amp;player_id=0&amp;app_id=58479" width="1280" height="720" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" title="tree - checking GS results"></iframe>

<p><a href="https://josepedrodias.com/gaussian/#3">tree GS</a></p>
<img src="2023-10-08/tree_pg.png" alt="tree photogrametry" title="tree photogrametry" width="50%">

<p>The tree stands near a road and that made me leave some overlapping gaps as I haven&#39;t taken pictures in the middle of the road. Tried to do a 360 and then captured a few extra details.</p>
<p>The tree was a mess. I believe colmap couldn&#39;t figure out 2/3 of the poses I captured and either skipped them entirely or integrated them badly. I guess the former happened. The training time was stalling (30-40 min to 2h...) and once I used the viewer on early results I could see only half of the tree was &#39;seen&#39; and many features were misiniterpreted. The photogrammetry results also only used the same subset of angles (clearly a capturing issue on my part) - not horrible results but got only a very partial surface sampled.</p>
<h2>building facades</h2>
<p><a href="2023-10-08/n32.jpg"><img src="2023-10-08/n32.jpg" alt="building source images" title="building" width="50%"></a></p>
<iframe src="https://player.vimeo.com/video/872321307?badge=0&amp;autopause=0&amp;quality_selector=1&amp;progress_bar=1&amp;player_id=0&amp;app_id=58479" width="1280" height="720" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" title="building facade - checking GS results"></iframe>

<p><a href="https://josepedrodias.com/gaussian/#4">building facade GS</a></p>
<img src="2023-10-08/n32_pg.png" alt="building photogrammetry" title="building photogrammetry" width="50%">

<p>For the building facades, I placed myself the furthest away and did vertical sweeps of 2 angle shots, moving in an arc to keep myself parallel to those facades.</p>
<p>The result wasn&#39;t as bad as the tree but there were a couple of prevalent problems: the presence of many different cars in the foreground added noise and the palm trees near the entrance ruined the wall behind them and due to the fact I did overall an arc of &lt; 180 degrees with lots of sky in frame, that resulted in many flying sky blobs around the scene.</p>
<h2>my living room couch</h2>
<p><a href="2023-10-08/sofa.jpg"><img src="2023-10-08/sofa.jpg" alt="couch source images" title="couch" width="50%"></a></p>
<iframe src="https://player.vimeo.com/video/872320478?badge=0&amp;autopause=0&amp;quality_selector=1&amp;progress_bar=1&amp;player_id=0&amp;app_id=58479" width="1280" height="720" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" title="couch - checking GS results"></iframe>

<p><a href="https://josepedrodias.com/gaussian/#5">couch GS</a></p>
<img src="2023-10-08/sofa_pg.png" alt="couch photogrammetry" title="couch photogrammetry" width="50%">

<p>Since I was getting worse and worse results and felt most of the problem had to do with such few poses and overlap, I decided to capture my living room couch using video. Used ffmpeg to extract 2 frames/sec out of it. This resulted in using &gt; 100 not-so-focused pictures with a lot of overlap. Interestingly enough, GS training doesn&#39;t suffer much from adding more pictures, doesn&#39;t seem to scale linearly with them at least. The results were ok for the effort I put. The lighting wasn&#39;t great to begin with and I got many wall blobs floating around, as had happened with the building facade. Seems like starting from video is a better compromise as it makes sure we keep plenty of overlap, which colmap seemed to have loved.</p>
<h2>conclusions</h2>
<p>Now, some considerations about photogrammetry vs gaussian splatting. With PG you tend to get a lot less of the model captured but doesn&#39;t often show incorrect data (you can have the surface with holes, but what&#39;s meshed is mostly correct). The GS result is completely different: it tries to paint blobs to match what was seen from every given angle and when information lacks it often assumes things are closer than they actually are. This is the main source of those annoying floating solid blobs. I will attempt to capture with multiple passes over the scene to try to pin any solid surfaces near the vicinity of the captured scene.<br>One thing I liked to do on early models was to crop the scene to a meaningful box. That works well for super controlled and small scenes such as the wooden house or a shopping item such as a shoe, but on outside scenes, cropping the surroundings keeps the technique from illustrating the overall environment, which is a great feature of GS.</p>
<p>We&#39;re still in the infancy of using this technique. Most viewers I got my hands on offer a sufferable navigating experience (I&#39;m publishing mine with <a href="https://github.com/antimatter15/splat">splat</a>. I would much rather use <a href="https://gsplat.tech/">gsplat</a> which offers orbit controls but it&#39;s closed source and the GS massaging one has to perform isn&#39;t public). It&#39;s super important to start from a recognizable point of view and having the scene properly aligned to begin with to be able to move around. I&#39;ll eventually replace or hack a different viewer.</p>
<p>As for capturing and preparation of GS content, there&#39;s room for improvement. If one could integrate the depth data of iPhones and such on indoor pictures, for those scenes we would minimize the presence of faulty floating splats. Having tools to select and move or delete faulty splats would be great too.</p>
  </body>
</html>
